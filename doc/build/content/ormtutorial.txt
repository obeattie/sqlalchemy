Object Relational Tutorial {@name=datamapping}
============

In this tutorial we will cover a basic SQLAlchemy object-relational mapping scenario, where we store and retrieve Python objects from a database representation.  The tutorial is in doctest format, meaning each `>>>` line represents something you can type at a Python command prompt, and the following text represents the expected return value.

## Version Check

A quick check to verify that we are on at least **version 0.5** of SQLAlchemy:

    {python}
    >>> import sqlalchemy
    >>> sqlalchemy.__version__ # doctest:+SKIP
    0.5.0
    
## Connecting

For this tutorial we will use an in-memory-only SQLite database.  To connect we use `create_engine()`:

    {python}
    >>> from sqlalchemy import create_engine
    >>> engine = create_engine('sqlite:///:memory:', echo=True)
    
The `echo` flag is a shortcut to setting up SQLAlchemy logging, which is accomplished via Python's standard `logging` module.  With it enabled, we'll see all the generated SQL produced.  If you are working through this tutorial and want less output generated, set it to `False`.   This tutorial will format the SQL behind a popup window so it doesn't get in our way; just click the "SQL" links to see whats being generated.
    
## Define and Create a Table {@name=tables}

Next we want to tell SQLAlchemy about our tables.  We will start with just a single table called `users`, which will store records for the end-users using our application (lets assume it's a website).  We define our tables within a catalog called `MetaData`, using the `Table` construct, which is used in a manner similar to SQL's CREATE TABLE syntax:

    {python}
    >>> from sqlalchemy import Table, Column, Integer, String, MetaData, ForeignKey    
    >>> metadata = MetaData()
    >>> users_table = Table('users', metadata,
    ...     Column('id', Integer, primary_key=True),
    ...     Column('name', String),
    ...     Column('fullname', String),
    ...     Column('password', String)
    ... )

All about how to define `Table` objects, as well as how to load their definition from an existing database (known as **reflection**), is described in [metadata](rel:metadata).

Next, we can issue CREATE TABLE statements derived from our table metadata, by calling `create_all()` and passing it the `engine` instance which points to our database.  This will check for the presence of a table first before creating, so it's safe to call multiple times:

    {python}
    {sql}>>> metadata.create_all(engine) # doctest:+ELLIPSIS,+NORMALIZE_WHITESPACE
    PRAGMA table_info("users")
    {}
    CREATE TABLE users (
        id INTEGER NOT NULL, 
        name VARCHAR, 
        fullname VARCHAR, 
        password VARCHAR, 
        PRIMARY KEY (id)
    )
    {}
    COMMIT

Users familiar with the syntax of CREATE TABLE may notice that the VARCHAR columns were generated without a length; on SQLite, this is a valid datatype, but on most databases it's not allowed.  So if running this tutorial on a database such as Postgres or MySQL, and you wish to use SQLAlchemy to generate the tables, a "length" may be provided to the `String` type as below:

    {python}
    Column('name', String(50))
    
The length field on `String`, as well as similar precision/scale fields available on `Integer`, `Numeric`, etc. are not referenced by SQLAlchemy other than when creating tables.

## Define a Python Class to be Mapped {@name=mapping}

While the `Table` object defines information about our database, it does not say anything about the definition or behavior of the business objects used by our application;  SQLAlchemy views this as a separate concern.  To correspond to our `users` table, let's create a rudimentary `User` class.  It only need subclass Python's built-in `object` class (i.e. it's a new style class):

    {python}
    >>> class User(object):
    ...     def __init__(self, name, fullname, password):
    ...         self.name = name
    ...         self.fullname = fullname
    ...         self.password = password
    ...
    ...     def __repr__(self):
    ...        return "<User('%s','%s', '%s')>" % (self.name, self.fullname, self.password)

The class has an `__init__()` and a `__repr__()` method for convenience.  These methods are both entirely optional, and can be of any form.  SQLAlchemy never calls `__init__()` directly.

## Setting up the Mapping

With our `users_table` and `User` class, we now want to map the two together.  That's where the SQLAlchemy ORM package comes in.  We'll use the `mapper` function to create a **mapping** between `users_table` and `User`:

    {python}
    >>> from sqlalchemy.orm import mapper
    >>> mapper(User, users_table) # doctest:+ELLIPSIS,+NORMALIZE_WHITESPACE
    <Mapper at 0x...; User>
    
The `mapper()` function creates a new `Mapper` object and stores it away for future reference, associated with our class.  Let's now create and inspect a `User` object:

    {python}
    >>> ed_user = User('ed', 'Ed Jones', 'edspassword')
    >>> ed_user.name
    'ed'
    >>> ed_user.password
    'edspassword'
    >>> str(ed_user.id)
    'None'
    
The `id` attribute, which while not defined by our `__init__()` method, exists due to the `id` column present within the `users_table` object.  By default, the `mapper` creates class attributes for all columns present within the `Table`.  These class attributes exist as Python descriptors, and define **instrumentation** for the mapped class.  The functionality of this instrumentation is very rich and includes the ability to track modifications and automatically load new data from the database when needed.

Since we have not yet told SQLAlchemy to persist `Ed Jones` within the database, its id is `None`.  When we persist the object later, this attribute will be populated with a newly generated value.

## Creating Table, Class and Mapper All at Once Declaratively {@name=declarative}

The preceding approach to configuration involving a `Table`, user-defined class, and `mapper()` call illustrate classical SQLAlchemy usage, which values the highest separation of concerns possible.  A large number of applications don't require this degree of separation, and for those SQLAlchemy offers an alternate "shorthand" configurational style called **declarative**.  For many applications, this is the only style of configuration needed.  Our above example using this style is as follows:

    {python}
    >>> from sqlalchemy.ext.declarative import declarative_base
    
    >>> Base = declarative_base()
    >>> class User(Base):
    ...     __tablename__ = 'users'
    ...
    ...     id = Column(Integer, primary_key=True)
    ...     name = Column(String)
    ...     fullname = Column(String)
    ...     password = Column(String)
    ...
    ...     def __init__(self, name, fullname, password):
    ...         self.name = name
    ...         self.fullname = fullname
    ...         self.password = password
    ...
    ...     def __repr__(self):
    ...        return "<User('%s','%s', '%s')>" % (self.name, self.fullname, self.password)

Above, the `declarative_base()` function defines a new class which we name `Base`, from which all of our ORM-enabled classes will derive.  Note that we define `Column` objects with no "name" field, since it's inferred from the given attribute name.

The underlying `Table` object created by our `declarative_base()` version of `User` is accessible via the `__table__` attribute:

    {python}
    >>> users_table = User.__table__
    
and the owning `MetaData` object is available as well:

    {python}
    >>> metadata = Base.metadata

Yet another "declarative" method is available for SQLAlchemy as a third party library called [Elixir](http://elixir.ematia.de/).  This is a full-featured configurational product which also includes many higher level mapping configurations built in.  Like declarative, once classes and mappings are defined, ORM usage is the same as with a classical SQLAlchemy configuration.

## Creating a Session

We're now ready to start talking to the database.  The ORM's "handle" to the database is the `Session`.  When we first set up the application, at the same level as our `create_engine()` statement, we define a `Session` class which will serve as a factory for new `Session` objects:

    {python}
    >>> from sqlalchemy.orm import sessionmaker
    >>> Session = sessionmaker(bind=engine)

In the case where your application does not yet have an `Engine` when you define your module-level objects, just set it up like this:

    {python}
    >>> Session = sessionmaker()

Later, when you create your engine with `create_engine()`, connect it to the `Session` using `configure()`:

    {python}
    >>> Session.configure(bind=engine)  # once engine is available
    
This custom-made `Session` class will create new `Session` objects which are bound to our database.  Other transactional characteristics may be defined when calling `sessionmaker()` as well; these are described in a later chapter.  Then, whenever you need to have a conversation with the database, you instantiate a `Session`:

    {python}
    >>> session = Session()
    
The above `Session` is associated with our SQLite `engine`, but it hasn't opened any connections yet.  When it's first used, it retrieves a connection from a pool of connections maintained by the `engine`, and holds onto it until we commit all changes and/or close the session object.

## Adding new Objects

To persist our `User` object, we `add()` it to our `Session`:

    {python}
    >>> ed_user = User('ed', 'Ed Jones', 'edspassword')
    >>> session.add(ed_user)
    
At this point, the instance is **pending**; no SQL has yet been issued.  The `Session` will issue the SQL to persist `Ed Jones` as soon as is needed, using a process known as a **flush**.  If we query the database for `Ed Jones`, all pending information will first be flushed, and the query is issued afterwards.

For example, below we create a new `Query` object which loads instances of `User`.  We "filter by" the `name` attribute of `ed`, and indicate that we'd like only the first result in the full list of rows.  A `User` instance is returned which is equivalent to that which we've added:

    {python}
    {sql}>>> our_user = session.query(User).filter_by(name='ed').first() # doctest:+ELLIPSIS,+NORMALIZE_WHITESPACE
    BEGIN
    INSERT INTO users (name, fullname, password) VALUES (?, ?, ?)
    ['ed', 'Ed Jones', 'edspassword']
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.name = ? ORDER BY users.oid 
     LIMIT 1 OFFSET 0
    ['ed']
    {stop}>>> our_user
    <User('ed','Ed Jones', 'edspassword')>

In fact, the `Session` has identified that the row returned is the **same** row as one already represented within its internal map of objects, so we actually got back the identical instance as that which we just added:

    {python}
    >>> ed_user is our_user
    True

The ORM concept at work here is known as an **identity map** and ensures that all operations upon a particular row within a `Session` operate upon the same set of data.  Once an object with a particular primary key is present in the `Session`, all SQL queries on that `Session` will always return the same Python object for that particular primary key; it also will raise an error if an attempt is made to place a second, already-persisted object with the same primary key within the session.

We can add more `User` objects at once using `add_all()`:

    {python}
    >>> session.add_all([
    ...     User('wendy', 'Wendy Williams', 'foobar'),
    ...     User('mary', 'Mary Contrary', 'xxg527'),
    ...     User('fred', 'Fred Flinstone', 'blah')])

Also, Ed has already decided his password isn't too secure, so lets change it:
    
    {python}
    >>> ed_user.password = 'f8s7ccs'

The `Session` is paying attention.  It knows, for example, that `Ed Jones` has been modified:
    
    {python}
    >>> session.dirty
    IdentitySet([<User('ed','Ed Jones', 'f8s7ccs')>])
    
and that three new `User` objects are pending:

    {python}
    >>> session.new  # doctest: +NORMALIZE_WHITESPACE
    IdentitySet([<User('wendy','Wendy Williams', 'foobar')>, 
    <User('mary','Mary Contrary', 'xxg527')>, 
    <User('fred','Fred Flinstone', 'blah')>])
    
We tell the `Session` that we'd like to issue all remaining changes to the database and commit the transaction, which has been in progress throughout.  We do this via `commit()`:

    {python}
    {sql}>>> session.commit()
    UPDATE users SET password=? WHERE users.id = ?
    ['f8s7ccs', 1]
    INSERT INTO users (name, fullname, password) VALUES (?, ?, ?)
    ['wendy', 'Wendy Williams', 'foobar']
    INSERT INTO users (name, fullname, password) VALUES (?, ?, ?)
    ['mary', 'Mary Contrary', 'xxg527']
    INSERT INTO users (name, fullname, password) VALUES (?, ?, ?)
    ['fred', 'Fred Flinstone', 'blah']
    COMMIT

`commit()` flushes whatever remaining changes remain to the database, and commits the transaction.  The connection resources referenced by the session are now returned to the connection pool.  Subsequent operations with this session will occur in a **new** transaction, which will again re-acquire connection resources when first needed.

If we look at Ed's `id` attribute, which earlier was `None`, it now has a value:

    {python}
    {sql}>>> ed_user.id # doctest: +NORMALIZE_WHITESPACE
    BEGIN
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.id = ?
    [1]
    {stop}1

After the `Session` inserts new rows in the database, all newly generated identifiers and database-generated defaults become available on the instance, either immediately or via load-on-first-access.  In this case, the entire row was re-loaded on access because a new transaction was begun after we issued `commit()`.  SQLAlchemy by default refreshes data from a previous transaction the first time it's accessed within a new transaction, so that the most recent state is available.  The level of reloading is configurable as is described in the chapter on Sessions.

## Querying

A `Query` is created using the `query()` function on `Session`.  This function takes a variable number of arguments, which can be any combination of classes and class-instrumented descriptors.  Below, we indicate a `Query` which loads `User` instances.  When evaluated in an iterative context, the list of `User` objects present is returned:

    {python}
    {sql}>>> for instance in session.query(User): # doctest: +NORMALIZE_WHITESPACE
    ...     print instance.name, instance.fullname 
    SELECT users.id AS users_id, users.name AS users_name, 
    users.fullname AS users_fullname, users.password AS users_password 
    FROM users ORDER BY users.oid
    []
    {stop}ed Ed Jones
    wendy Wendy Williams
    mary Mary Contrary
    fred Fred Flinstone

The `Query` also accepts ORM-instrumented descriptors as arguments.  Any time multiple class entities or column-based entities are expressed as arguments to the `query()` function, the return result is expressed as tuples:

    {python}
    {sql}>>> for name, fullname in session.query(User.name, User.fullname): # doctest: +NORMALIZE_WHITESPACE
    ...     print name, fullname
    SELECT users.name AS users_name, users.fullname AS users_fullname
    FROM users
    []
    {stop}ed Ed Jones
    wendy Wendy Williams
    mary Mary Contrary
    fred Fred Flinstone

Basic operations with `Query` include issuing LIMIT and OFFSET, most conveniently using Python array slices and typically in conjunction with ORDER BY:

    {python}
    {sql}>>> for u in session.query(User).order_by(User.id)[1:3]: #doctest: +NORMALIZE_WHITESPACE
    ...    print u
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users ORDER BY users.id 
    LIMIT 2 OFFSET 1
    []
    {stop}<User('wendy','Wendy Williams', 'foobar')>
    <User('mary','Mary Contrary', 'xxg527')>

and filtering results, which is accomplished either with `filter_by()`, which uses keyword arguments:

    {python}
    {sql}>>> for name, in session.query(User.name).filter_by(fullname='Ed Jones'): # doctest: +NORMALIZE_WHITESPACE
    ...    print name
    SELECT users.name AS users_name FROM users 
    WHERE users.fullname = ?
    ['Ed Jones']
    {stop}ed

...or `filter()`, which uses more flexible SQL expression language constructs.  These allow you to use regular Python operators with the class-level attributes on your mapped class:

    {python}
    {sql}>>> for name, in session.query(User.name).filter(User.fullname=='Ed Jones'): # doctest: +NORMALIZE_WHITESPACE
    ...    print name
    SELECT users.name AS users_name FROM users 
    WHERE users.fullname = ?
    ['Ed Jones']
    {stop}ed

The `Query` object is fully *generative*, meaning that most method calls return a new `Query` object upon which further criteria may be added.  For example, to query for users named "ed" with a full name of "Ed Jones", you can call `filter()` twice, which joins criteria using `AND`:

    {python}
    {sql}>>> for user in session.query(User).filter(User.name=='ed').filter(User.fullname=='Ed Jones'): # doctest: +NORMALIZE_WHITESPACE
    ...    print user
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.name = ? AND users.fullname = ? ORDER BY users.oid
    ['ed', 'Ed Jones']
    {stop}<User('ed','Ed Jones', 'f8s7ccs')>


### Common Filter Operators

Here's a rundown of some of the most common operators used in `filter()`:

  * equals

        {python}
        query.filter(User.name == 'ed')
    
  * not equals
    
        {python}
        query.filter(User.name != 'ed')
    
  * LIKE
    
        {python}
        query.filter(User.name.like('%ed%'))
        
  * IN
    
        {python}
        query.filter(User.name.in_(['ed', 'wendy', 'jack']))
        
  * IS NULL
    
        {python}
        filter(User.name == None)
        
  * AND
    
        {python}
        from sqlalchemy import and_
        filter(and_(User.name == 'ed', User.fullname == 'Ed Jones'))
        
        # or call filter()/filter_by() multiple times
        filter(User.name == 'ed').filter(User.fullname == 'Ed Jones')
    
  * OR
        
        {python}
        from sqlalchemy import or_
        filter(or_(User.name == 'ed', User.name == 'wendy'))
        
### Returning Lists and Scalars {@name=scalars}

The `all()`, `one()`, and `first()` methods of `Query` immediately issue SQL without using an iterative context or array index.  `all()` returns a list:

    {python}
    >>> query = session.query(User).filter(User.name.like('%ed'))

    {sql}>>> query.all()
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.name LIKE ? ORDER BY users.oid
    ['%ed']
    {stop}[<User('ed','Ed Jones', 'f8s7ccs')>, <User('fred','Fred Flinstone', 'blah')>]

`first()` applies a limit of one and returns the first result as a scalar:

    {python}
    {sql}>>> query.first()
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.name LIKE ? ORDER BY users.oid 
     LIMIT 1 OFFSET 0
    ['%ed']
    {stop}<User('ed','Ed Jones', 'f8s7ccs')>

and `one()`, applies a limit of *two*, and if not exactly one row returned (no more, no less), raises an error:

    {python}
    {sql}>>> try:  
    ...     user = query.one() 
    ... except Exception, e: 
    ...     print e
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.name LIKE ? ORDER BY users.oid 
     LIMIT 2 OFFSET 0
    ['%ed']
    {stop}Multiple rows returned for one()

### Using Literal SQL {@naqme=literal}

Literal strings can be used flexibly with `Query`.  Most methods accept strings in addition to SQLAlchemy clause constructs.  For example, `filter()`:

    {python}
    {sql}>>> for user in session.query(User).filter("id<224").all():
    ...     print user.name
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE id<224 ORDER BY users.oid
    []
    {stop}ed
    wendy
    mary
    fred
    
Bind parameters can be specified with string-based SQL, using a colon.  To specify the values, use the `params()` method:

    {python}
    {sql}>>> session.query(User).filter("id<:value and name=:name").\
    ...     params(value=224, name='fred').one() # doctest: +NORMALIZE_WHITESPACE
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE id<? and name=? ORDER BY users.oid 
    LIMIT 2 OFFSET 0
    [224, 'fred']
    {stop}<User('fred','Fred Flinstone', 'blah')>

To use an entirely string-based statement, using `from_statement()`; just ensure that the columns clause of the statement contains the column names normally used by the mapper (below illustrated using an asterisk):

    {python}
    {sql}>>> session.query(User).from_statement("SELECT * FROM users where name=:name").params(name='ed').all()
    SELECT * FROM users where name=?
    ['ed']
    {stop}[<User('ed','Ed Jones', 'f8s7ccs')>]

## Building a Relation {@name=relation}

Now let's consider a second table to be dealt with.  Users in our system also can store any number of email addresses associated with their username.  This implies a basic one to many association from the `users_table` to a new table which stores email addresses, which we will call `addresses`.  Using declarative, we define this table along with its mapped class, `Address`:

    {python}
    >>> from sqlalchemy import ForeignKey
    >>> from sqlalchemy.orm import relation
    >>> class Address(Base):
    ...     __tablename__ = 'addresses'
    ...     id = Column(Integer, primary_key=True)
    ...     email_address = Column(String, nullable=False)
    ...     user_id = Column(Integer, ForeignKey('users.id'))
    ...
    ...     user = relation(User, backref='addresses')
    ...
    ...     def __init__(self, email_address):
    ...         self.email_address = email_address
    ...
    ...     def __repr__(self):
    ...         return "<Address('%s')>" % self.email_address

The above class introduces a **foreign key** constraint which references the `users` table.  This defines for SQLAlchemy the relationship between the two tables at the database level.  The relationship between the `User` and `Address` classes is defined separately using the `relation()` function, which defines an attribute `user` to be placed on the `Address` class, as well as an `addresses` collection to be placed on the `User` class.  Such a relation is known as a **bidirectional** relationship.   Because of the placement of the foreign key, from `Address` to `User` it is **many to one**, and from `User` to `Address` it is **one to many**.  SQLAlchemy figures this out for you and is not explicitly stated.

The `relation()` function is extremely flexible, and could just have easily been defined on the `User` class:

    {python}
    class User(Base):
        ....
        addresses = relation("Address", backref="user")
        
Where above we used the string name `"Addresses"` in the event that the `Address` class was not yet defined.   We are also free to not define a backref, and to define the `relation()` only on one class and not the other.

We'll need to create the `addresses` table in the database, so we will issue another CREATE from our metadata, which will skip over tables which have already been created:

    {python}
    {sql}>>> metadata.create_all(engine) # doctest: +NORMALIZE_WHITESPACE
    PRAGMA table_info("users")
    {}
    PRAGMA table_info("addresses")
    {}
    CREATE TABLE addresses (
        id INTEGER NOT NULL, 
        email_address VARCHAR NOT NULL, 
        user_id INTEGER, 
        PRIMARY KEY (id), 
         FOREIGN KEY(user_id) REFERENCES users (id)
    )
    {}
    COMMIT

## Working with Related Objects {@name=related_objects}

Now when we create a `User`, a blank `addresses` collection will be present.  By default, the collection is a Python list.  Other collection types, such as sets and dictionaries, are available as well:

    {python}
    >>> jack = User('jack', 'Jack Bean', 'gjffdd')
    >>> jack.addresses
    []
    
We are free to add `Address` objects on our `User` object.  In this case we just assign a full list directly:

    {python}
    >>> jack.addresses = [Address(email_address='jack@google.com'), Address(email_address='j25@yahoo.com')]

When using a bidirectional relationship, elements added in one direction automatically become visible in the other direction.  This is the basic behavior of the **backref** keyword, which maintains the relationship purely in memory, without using any SQL:

    {python}
    >>> jack.addresses[1]
    <Address('j25@yahoo.com')>
    
    >>> jack.addresses[1].user
    <User('jack','Jack Bean', 'gjffdd')>

Let's add and commit `Jack Bean` to the database:

    {python}
    >>> session.add(jack)
    {sql}>>> session.commit()
    INSERT INTO users (name, fullname, password) VALUES (?, ?, ?)
    ['jack', 'Jack Bean', 'gjffdd']
    INSERT INTO addresses (email_address, user_id) VALUES (?, ?)
    ['jack@google.com', 5]
    INSERT INTO addresses (email_address, user_id) VALUES (?, ?)
    ['j25@yahoo.com', 5]
    COMMIT
    
Querying for Jack, we get just Jack back.  No SQL is yet issued for for Jack's addresses:

    {python}
    {sql}>>> jack = session.query(User).filter_by(name='jack').one()
    BEGIN
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.name = ? ORDER BY users.oid 
     LIMIT 2 OFFSET 0
    ['jack']
    
    >>> jack
    <User('jack','Jack Bean', 'gjffdd')>
    
Let's look at the `addresses` collection.  Watch the SQL:

    {python}
    {sql}>>> jack.addresses
    SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
    FROM addresses 
    WHERE ? = addresses.user_id ORDER BY addresses.oid
    [5]
    {stop}[<Address('jack@google.com')>, <Address('j25@yahoo.com')>]
    
When we accessed the `addresses` collection, SQL was suddenly issued.  This is an example of a **lazy loading relation**.
    
If you want to reduce the number of queries (dramatically, in many cases), we can apply an **eager load** to the query operation.   With the same query, we may apply an **option** to the query, indicating that we'd like `addresses` to load "eagerly".  SQLAlchemy then constructs an outer join between the `users` and `addresses` tables, and loads them at once, populating the `addresses` collection on each `User` object if it's not already populated:

    {python}
    >>> from sqlalchemy.orm import eagerload
    
    {sql}>>> jack = session.query(User).options(eagerload('addresses')).filter_by(name='jack').one() #doctest: +NORMALIZE_WHITESPACE
    SELECT anon_1.users_id AS anon_1_users_id, anon_1.users_name AS anon_1_users_name, 
    anon_1.users_fullname AS anon_1_users_fullname, anon_1.users_password AS anon_1_users_password, 
    addresses_1.id AS addresses_1_id, addresses_1.email_address AS addresses_1_email_address, 
    addresses_1.user_id AS addresses_1_user_id 
        FROM (SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, 
        users.password AS users_password, users.oid AS users_oid 
        FROM users 
        WHERE users.name = ? ORDER BY users.oid 
         LIMIT 2 OFFSET 0) AS anon_1 LEFT OUTER JOIN addresses AS addresses_1 
         ON anon_1.users_id = addresses_1.user_id ORDER BY anon_1.oid, addresses_1.oid
        ['jack']
    
    >>> jack
    <User('jack','Jack Bean', 'gjffdd')>
    
    >>> jack.addresses
    [<Address('jack@google.com')>, <Address('j25@yahoo.com')>]

SQLAlchemy has the ability to control exactly which attributes and how many levels deep should be joined together in a single SQL query.  More information on this feature is available in [advdatamapping_relation](rel:advdatamapping_relation).

## Querying with Joins {@name=joins}

While the eager load created a JOIN specifically to populate a collection, we can also work explicitly with joins in many ways.  For example, to construct a simple inner join between `User` and `Address`, we can just `filter()` their related columns together:

    {python}
    {sql}>>> for u, a in session.query(User, Address).filter(User.id==Address.user_id).\
    ...         filter(Address.email_address=='jack@google.com').all():   # doctest: +NORMALIZE_WHITESPACE
    ...     print u, a
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, 
    users.password AS users_password, addresses.id AS addresses_id, 
    addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
    FROM users, addresses 
    WHERE users.id = addresses.user_id AND addresses.email_address = ? ORDER BY users.oid
    ['jack@google.com']
    {stop}<User('jack','Jack Bean', 'gjffdd')> <Address('jack@google.com')>

Or we can make a real JOIN construct; one way to do so is to use the ORM `join()` function, and tell `Query` to "select from" this join:

    {python}
    >>> from sqlalchemy.orm import join
    {sql}>>> session.query(User).select_from(join(User, Address)).\
    ...         filter(Address.email_address=='jack@google.com').all()
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users JOIN addresses ON users.id = addresses.user_id 
    WHERE addresses.email_address = ? ORDER BY users.oid
    ['jack@google.com']
    {stop}[<User('jack','Jack Bean', 'gjffdd')>]

`join()` knows how to join between `User` and `Address` because there's only one foreign key between them.  If there were no foreign keys, or several, `join()` would require a third argument indicating the ON clause of the join, in one of the following:

    {python}
    join(User, Address, User.id==Address.user_id)  # explicit condition
    join(User, Address, User.addresses)            # specify relation from left to right
    join(User, Address, 'addresses')               # same, using a string
    
The functionality of `join()` is also available generatively from `Query` itself using `Query.join`.  This method takes a relation descriptor or string name of a relation as its argument:

    {python}
    {sql}>>> session.query(User).join(User.addresses).\
    ...     filter(Address.email_address=='jack@google.com').all()
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users JOIN addresses ON users.id = addresses.user_id 
    WHERE addresses.email_address = ? ORDER BY users.oid
    ['jack@google.com']
    {stop}[<User('jack','Jack Bean', 'gjffdd')>]

`Query.join()` can also take a list of relation/string elements as its argument, indicating multiple joins along a path of relations:

    {python}
    session.query(Foo).join([Foo.bars, 'bats', 'widgets']).filter(...)
    
### Using Aliases {@name=aliases}

When querying across multiple tables, if the same table needs to be referenced more than once, SQL typically requires that the table be *aliased* with another name, so that it can be distinguished against other occurences of that table.  The `Query` supports this most expicitly using the `aliased` construct.  Below we join to the `Address` entity twice, to locate a user who has two distinct email addresses at the same time:

    {python}
    >>> from sqlalchemy.orm import aliased
    >>> adalias1 = aliased(Address)
    >>> adalias2 = aliased(Address)
    {sql}>>> for username, email1, email2 in session.query(User.name, adalias1.email_address, adalias2.email_address).\
    ...     select_from(join(User, adalias1).join(adalias2)).\
    ...     filter(adalias1.email_address=='jack@google.com').\
    ...     filter(adalias2.email_address=='j25@yahoo.com'):
    ...     print username, email1, email2      # doctest: +NORMALIZE_WHITESPACE
    SELECT users.name AS users_name, addresses_1.email_address AS addresses_1_email_address, 
    addresses_2.email_address AS addresses_2_email_address 
    FROM users JOIN addresses AS addresses_1 ON users.id = addresses_1.user_id 
    JOIN addresses AS addresses_2 ON users.id = addresses_2.user_id 
    WHERE addresses_1.email_address = ? AND addresses_2.email_address = ?
    ['jack@google.com', 'j25@yahoo.com']
    {stop}jack jack@google.com j25@yahoo.com

The inline form of `join` can accomplish the above result using tuples for arguments, each expressing the ON clause and target entity:

    {python}
    session.query(User.name, adalias1.email_address, adalias2.email_address).\
        join([(User.addresses, adalias1), (User.addresses, adalias2)])
        
### Relation Operators

A summary of all operators usable on relations:

* Filter on explicit column criterion, combined with a join.  Column criterion can make usage of all supported SQL operators and expression constructs:

        {python}
        {sql}>>> session.query(User).join('addresses').\
        ...    filter(Address.email_address=='jack@google.com').all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users JOIN addresses ON users.id = addresses.user_id 
        WHERE addresses.email_address = ? ORDER BY users.oid
        ['jack@google.com']
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]

    Criterion placed in `filter()` usually correspond to the last `join()` call; if the join was specified with `aliased=True`, class-level criterion against the join's target (or targets) will be appropriately aliased as well.  

        {python}
        {sql}>>> session.query(User).join('addresses', aliased=True).\
        ...    filter(Address.email_address=='jack@google.com').all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users JOIN addresses AS addresses_1 ON users.id = addresses_1.user_id 
        WHERE addresses_1.email_address = ? ORDER BY users.oid
        ['jack@google.com']
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]

* Filter_by on key=value criterion, combined with a join.  Same as `filter()` on column criterion except keyword arguments are used.

        {python}
        {sql}>>> session.query(User).join('addresses').\
        ...    filter_by(email_address='jack@google.com').all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users JOIN addresses ON users.id = addresses.user_id 
        WHERE addresses.email_address = ? ORDER BY users.oid
        ['jack@google.com']
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]
    
* Filter on explicit column criterion using `any()` (for collections) or `has()` (for scalar relations).  This is a more succinct method than joining, as an `EXISTS` subquery is generated automatically.  `any()` means, "find all parent items where any child item of its collection meets this criterion":

        {python}
        {sql}>>> session.query(User).\
        ...    filter(User.addresses.any(Address.email_address=='jack@google.com')).all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users 
        WHERE EXISTS (SELECT 1 
        FROM addresses 
        WHERE users.id = addresses.user_id AND addresses.email_address = ?) ORDER BY users.oid
        ['jack@google.com']
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]

    `has()` means, "find all parent items where the child item meets this criterion":

        {python}
        {sql}>>> session.query(Address).\
        ...    filter(Address.user.has(User.name=='jack')).all()
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE EXISTS (SELECT 1 
        FROM users 
        WHERE users.id = addresses.user_id AND users.name = ?) ORDER BY addresses.oid
        ['jack']
        {stop}[<Address('jack@google.com')>, <Address('j25@yahoo.com')>]

    Both `has()` and `any()` also accept keyword arguments which are interpreted against the child classes' attributes:

        {python}
        {sql}>>> session.query(User).\
        ...    filter(User.addresses.any(email_address='jack@google.com')).all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users 
        WHERE EXISTS (SELECT 1 
        FROM addresses 
        WHERE users.id = addresses.user_id AND addresses.email_address = ?) ORDER BY users.oid
        ['jack@google.com']
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]
    
* Filter_by on instance identity criterion.  When comparing to a related instance, `filter_by()` will in most cases not need to reference the child table, since a child instance already contains enough information with which to generate criterion against the parent table.  `filter_by()` uses an equality comparison for all relationship types.  For many-to-one and one-to-one, this represents all objects which reference the given child object:

        {python}
        # locate a user
        {sql}>>> user = session.query(User).filter(User.name=='jack').one() #doctest: +NORMALIZE_WHITESPACE
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users 
        WHERE users.name = ? ORDER BY users.oid 
        LIMIT 2 OFFSET 0
        ['jack']
        {stop}
        
        # use the user in a filter_by() expression
        {sql}>>> session.query(Address).filter_by(user=user).all()
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE ? = addresses.user_id ORDER BY addresses.oid
        [5]
        {stop}[<Address('jack@google.com')>, <Address('j25@yahoo.com')>]

    For one-to-many and many-to-many, it represents all objects which contain the given child object in the related collection:

        {python}
        # locate an address
        {sql}>>> address = session.query(Address).\
        ...    filter(Address.email_address=='jack@google.com').one() #doctest: +NORMALIZE_WHITESPACE
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE addresses.email_address = ? ORDER BY addresses.oid 
        LIMIT 2 OFFSET 0
        {stop}['jack@google.com']
    
        # use the address in a filter_by expression
        {sql}>>> session.query(User).filter_by(addresses=address).all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users 
        WHERE users.id = ? ORDER BY users.oid
        [5]
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]

* Select instances with a particular parent.  This is the "reverse" operation of filtering by instance identity criterion; the criterion is against a relation pointing *to* the desired class, instead of one pointing *from* it.  This will utilize the same "optimized" query criterion, usually not requiring any joins:

        {python}
        {sql}>>> session.query(Address).with_parent(user, property='addresses').all()
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE ? = addresses.user_id ORDER BY addresses.oid
        [5]
        {stop}[<Address('jack@google.com')>, <Address('j25@yahoo.com')>]
        
* Filter on a many-to-one/one-to-one instance identity criterion.  The class-level `==` operator will act the same as `filter_by()` for a scalar relation:

        {python}
        {sql}>>> session.query(Address).filter(Address.user==user).all()
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE ? = addresses.user_id ORDER BY addresses.oid
        [5]
        {stop}[<Address('jack@google.com')>, <Address('j25@yahoo.com')>]

    whereas the `!=` operator will generate a negated EXISTS clause:

        {python}
        {sql}>>> session.query(Address).filter(Address.user!=user).all()
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE NOT (EXISTS (SELECT 1 
        FROM users 
        WHERE users.id = addresses.user_id AND users.id = ?)) ORDER BY addresses.oid
        [5]
        {stop}[]

    a comparison to `None` also generates an IS NULL clause for a many-to-one relation:

        {python}
        {sql}>>> session.query(Address).filter(Address.user==None).all()
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE addresses.user_id IS NULL ORDER BY addresses.oid
        []
        {stop}[]

* Filter on a one-to-many instance identity criterion.  The `contains()` operator returns all parent objects which contain the given object as one of its collection members:

        {python}
        {sql}>>> session.query(User).filter(User.addresses.contains(address)).all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users 
        WHERE users.id = ? ORDER BY users.oid
        [5]
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]

* Filter on a multiple one-to-many instance identity criterion.  The `==` operator can be used with a collection-based attribute against a list of items, which will generate multiple `EXISTS` clauses:

        {python}
        {sql}>>> addresses = session.query(Address).filter(Address.user==user).all()
        SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
        FROM addresses 
        WHERE ? = addresses.user_id ORDER BY addresses.oid
        [5]
        {stop}
        
        {sql}>>> session.query(User).filter(User.addresses == addresses).all()
        SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
        FROM users 
        WHERE (EXISTS (SELECT 1 
        FROM addresses 
        WHERE users.id = addresses.user_id AND addresses.id = ?)) AND (EXISTS (SELECT 1 
        FROM addresses 
        WHERE users.id = addresses.user_id AND addresses.id = ?)) ORDER BY users.oid
        [1, 2]
        {stop}[<User('jack','Jack Bean', 'gjffdd')>]

## Deleting

Let's try to delete `jack` and see how that goes.  We'll mark as deleted in the session, then we'll issue a `count` query to see that no rows remain:

    {python}
    >>> session.delete(jack)
    {sql}>>> session.query(User).filter_by(name='jack').count() # doctest: +NORMALIZE_WHITESPACE
    UPDATE addresses SET user_id=? WHERE addresses.id = ?
    [None, 1]
    UPDATE addresses SET user_id=? WHERE addresses.id = ?
    [None, 2]
    DELETE FROM users WHERE users.id = ?
    [5]
    SELECT count(users.id) AS count_1
    FROM users 
    WHERE users.name = ?
    ['jack']
    {stop}0
    
So far, so good.  How about Jack's `Address` objects ?

    {python}
    {sql}>>> session.query(Address).filter(
    ...     Address.email_address.in_(['jack@google.com', 'j25@yahoo.com'])
    ...  ).count() # doctest: +NORMALIZE_WHITESPACE
    SELECT count(addresses.id) AS count_1
    FROM addresses 
    WHERE addresses.email_address IN (?, ?)
    ['jack@google.com', 'j25@yahoo.com']
    {stop}2
    
Uh oh, they're still there !  Analyzing the flush SQL, we can see that the `user_id` column of each address was set to NULL, but the rows weren't deleted.  SQLAlchemy doesn't assume that deletes cascade, you have to tell it so.

So let's rollback our work, and start fresh with new mappers that express the relationship the way we want:

    {python}
    {sql}>>> session.rollback()  # roll back the transaction
    ROLLBACK
    
    >>> session.clear() # clear the session
    >>> clear_mappers() # clear mappers
    
We need to tell the `addresses` relation on `User` that we'd like session.delete() operations to cascade down to the child `Address` objects.  Further, we also want `Address` objects which get detached from their parent `User`, whether or not the parent is deleted, to be deleted.  For these behaviors we use two **cascade options** `delete` and `delete-orphan`, using the string-based `cascade` option to the `relation()` function:

    {python}
    >>> mapper(User, users_table, properties={    # doctest: +ELLIPSIS
    ...     'addresses':relation(Address, backref='user', cascade="all, delete, delete-orphan")
    ... })
    <sqlalchemy.orm.mapper.Mapper object at 0x...>
    
    >>> mapper(Address, addresses_table) # doctest: +ELLIPSIS
    <sqlalchemy.orm.mapper.Mapper object at 0x...>

Now when we load Jack, removing an address from his `addresses` collection will result in that `Address` being deleted:

    {python}
    # load Jack by primary key
    {sql}>>> jack = session.query(User).get(jack.id)    #doctest: +NORMALIZE_WHITESPACE
    BEGIN
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.id = ?
    [5]
    {stop}
    
    # remove one Address (lazy load fires off)
    {sql}>>> del jack.addresses[1]  
    SELECT addresses.id AS addresses_id, addresses.email_address AS addresses_email_address, addresses.user_id AS addresses_user_id 
    FROM addresses 
    WHERE ? = addresses.user_id ORDER BY addresses.oid
    [5]
    {stop}
    
    # only one address remains
    {sql}>>> session.query(Address).filter(
    ...     Address.email_address.in_(['jack@google.com', 'j25@yahoo.com'])
    ... ).count() # doctest: +NORMALIZE_WHITESPACE
    DELETE FROM addresses WHERE addresses.id = ?
    [2]
    SELECT count(addresses.id) AS count_1
    FROM addresses 
    WHERE addresses.email_address IN (?, ?)
    ['jack@google.com', 'j25@yahoo.com']
    {stop}1
    
Deleting Jack will delete both Jack and his remaining `Address`:

    {python}
    >>> session.delete(jack)
    
    {sql}>>> session.commit()
    DELETE FROM addresses WHERE addresses.id = ?
    [1]
    DELETE FROM users WHERE users.id = ?
    [5]
    COMMIT
    {stop}
    
    {sql}>>> session.query(User).filter_by(name='jack').count() # doctest: +NORMALIZE_WHITESPACE
    BEGIN
    SELECT count(users.id) AS count_1
    FROM users 
    WHERE users.name = ?
    ['jack']
    {stop}0
    
    {sql}>>> session.query(Address).filter(
    ...    Address.email_address.in_(['jack@google.com', 'j25@yahoo.com'])
    ... ).count() # doctest: +NORMALIZE_WHITESPACE
    SELECT count(addresses.id) AS count_1
    FROM addresses 
    WHERE addresses.email_address IN (?, ?)
    ['jack@google.com', 'j25@yahoo.com']
    {stop}0

## Building a Many To Many Relation {@name=manytomany}

We're moving into the bonus round here, but lets show off a many-to-many relationship.  We'll sneak in some other features too, just to take a tour.  We'll make our application a blog application, where users can write `BlogPost`s, which have `Keywords` associated with them.

First some new tables:

    {python}
    >>> from sqlalchemy import Text
    >>> post_table = Table('posts', metadata, 
    ...        Column('id', Integer, primary_key=True),
    ...        Column('user_id', Integer, ForeignKey('users.id')),
    ...        Column('headline', String(255), nullable=False),
    ...        Column('body', Text)
    ...        )
    
    >>> post_keywords = Table('post_keywords', metadata,
    ...        Column('post_id', Integer, ForeignKey('posts.id')),
    ...        Column('keyword_id', Integer, ForeignKey('keywords.id')))
    
    >>> keywords_table = Table('keywords', metadata,
    ...        Column('id', Integer, primary_key=True),
    ...        Column('keyword', String(50), nullable=False, unique=True))
    
    {sql}>>> metadata.create_all(engine) # doctest: +NORMALIZE_WHITESPACE
    PRAGMA table_info("users")
    {}
    PRAGMA table_info("addresses")
    {}
    PRAGMA table_info("posts")
    {}
    PRAGMA table_info("keywords")
    {}
    PRAGMA table_info("post_keywords")
    {}
    CREATE TABLE posts (
        id INTEGER NOT NULL, 
        user_id INTEGER, 
        headline VARCHAR(255) NOT NULL, 
        body TEXT, 
        PRIMARY KEY (id), 
         FOREIGN KEY(user_id) REFERENCES users (id)
    )
    {}
    COMMIT
    CREATE TABLE keywords (
        id INTEGER NOT NULL, 
        keyword VARCHAR(50) NOT NULL, 
        PRIMARY KEY (id), 
         UNIQUE (keyword)
    )
    {}
    COMMIT
    CREATE TABLE post_keywords (
        post_id INTEGER, 
        keyword_id INTEGER, 
         FOREIGN KEY(post_id) REFERENCES posts (id), 
         FOREIGN KEY(keyword_id) REFERENCES keywords (id)
    )
    {}
    COMMIT

Then some classes:

    {python}
    >>> class BlogPost(object):
    ...     def __init__(self, headline, body, author):
    ...         self.author = author
    ...         self.headline = headline
    ...         self.body = body
    ...     def __repr__(self):
    ...         return "BlogPost(%r, %r, %r)" % (self.headline, self.body, self.author)
    
    >>> class Keyword(object):
    ...     def __init__(self, keyword):
    ...         self.keyword = keyword
            
And the mappers.  `BlogPost` will reference `User` via its `author` attribute:

    {python}
    >>> from sqlalchemy.orm import backref
    
    >>> mapper(Keyword, keywords_table) # doctest: +ELLIPSIS
    <sqlalchemy.orm.mapper.Mapper object at 0x...>
    
    >>> mapper(BlogPost, post_table, properties={   # doctest: +ELLIPSIS
    ...    'author':relation(User, backref=backref('posts', lazy='dynamic')),
    ...    'keywords':relation(Keyword, secondary=post_keywords)
    ... }) 
    <sqlalchemy.orm.mapper.Mapper object at 0x...>
    
There's three new things in the above mapper:

  * the `User` relation has a backref, like we've used before, except this time it references a function called `backref()`.  This function is used when yo'd like to specify keyword options for the backwards relationship.
  * the keyword option we specified to `backref()` is `lazy="dynamic"`.  This sets a default **loader strategy** on the attribute, in this case a special strategy that allows partial loading of results.
  * The `keywords` relation uses a keyword argument `secondary` to indicate the **association table** for the many to many relationship from `BlogPost` to `Keyword`.
    
Usage is not too different from what we've been doing.  Let's give Wendy some blog posts:

    {python}
    {sql}>>> wendy = session.query(User).filter_by(name='wendy').one()
    SELECT users.id AS users_id, users.name AS users_name, users.fullname AS users_fullname, users.password AS users_password 
    FROM users 
    WHERE users.name = ? ORDER BY users.oid 
     LIMIT 2 OFFSET 0
    ['wendy']
    
    >>> post = BlogPost("Wendy's Blog Post", "This is a test", wendy)
    >>> session.save(post)
    
We're storing keywords uniquely in the database, but we know that we don't have any yet, so we can just create them:

    {python}
    >>> post.keywords.append(Keyword('wendy'))
    >>> post.keywords.append(Keyword('firstpost'))
    
We can now look up all blog posts with the keyword 'firstpost'.   We'll use a special collection operator `any` to locate "blog posts where any of its keywords has the keyword string 'firstpost'":

    {python}
    {sql}>>> session.query(BlogPost).filter(BlogPost.keywords.any(keyword='firstpost')).all()
    INSERT INTO keywords (keyword) VALUES (?)
    ['wendy']
    INSERT INTO keywords (keyword) VALUES (?)
    ['firstpost']
    INSERT INTO posts (user_id, headline, body) VALUES (?, ?, ?)
    [2, "Wendy's Blog Post", 'This is a test']
    INSERT INTO post_keywords (post_id, keyword_id) VALUES (?, ?)
    [[1, 1], [1, 2]]
    SELECT posts.id AS posts_id, posts.user_id AS posts_user_id, posts.headline AS posts_headline, posts.body AS posts_body 
    FROM posts 
    WHERE EXISTS (SELECT 1 
    FROM post_keywords, keywords 
    WHERE posts.id = post_keywords.post_id AND keywords.id = post_keywords.keyword_id AND keywords.keyword = ?) ORDER BY posts.oid
    ['firstpost']
    {stop}[BlogPost("Wendy's Blog Post", 'This is a test', <User('wendy','Wendy Williams', 'foobar')>)]
    
If we want to look up just Wendy's posts, we can tell the query to narrow down to her as a parent:

    {python}
    {sql}>>> session.query(BlogPost).with_parent(wendy).\
    ... filter(BlogPost.keywords.any(keyword='firstpost')).all()
    SELECT posts.id AS posts_id, posts.user_id AS posts_user_id, posts.headline AS posts_headline, posts.body AS posts_body 
    FROM posts 
    WHERE ? = posts.user_id AND (EXISTS (SELECT 1 
    FROM post_keywords, keywords 
    WHERE posts.id = post_keywords.post_id AND keywords.id = post_keywords.keyword_id AND keywords.keyword = ?)) ORDER BY posts.oid
    [2, 'firstpost']
    {stop}[BlogPost("Wendy's Blog Post", 'This is a test', <User('wendy','Wendy Williams', 'foobar')>)]

Or we can use Wendy's own `posts` relation, which is a "dynamic" relation, to query straight from there:

    {python}
    {sql}>>> wendy.posts.filter(BlogPost.keywords.any(keyword='firstpost')).all()
    SELECT posts.id AS posts_id, posts.user_id AS posts_user_id, posts.headline AS posts_headline, posts.body AS posts_body 
    FROM posts 
    WHERE ? = posts.user_id AND (EXISTS (SELECT 1 
    FROM post_keywords, keywords 
    WHERE posts.id = post_keywords.post_id AND keywords.id = post_keywords.keyword_id AND keywords.keyword = ?)) ORDER BY posts.oid
    [2, 'firstpost']
    {stop}[BlogPost("Wendy's Blog Post", 'This is a test', <User('wendy','Wendy Williams', 'foobar')>)]

## Further Reference 

Generated Documentation for Query: [docstrings_sqlalchemy.orm.query_Query](rel:docstrings_sqlalchemy.orm.query_Query)

ORM Generated Docs: [docstrings_sqlalchemy.orm](rel:docstrings_sqlalchemy.orm)

Further information on mapping setups are in [advdatamapping](rel:advdatamapping).

Further information on working with Sessions: [unitofwork](rel:unitofwork).
